{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dougyd92/ML-Foudations/blob/main/Projects/Project_2_Bot_or_Not_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGjygYBRIs8I"
      },
      "source": [
        "# Project: Bot or Not? Detecting Fake Accounts with Classification\n",
        "\n",
        "*Machine Learning Foundations for Beginners*\n",
        "\n",
        "*Codecademy Live Learning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIW0UCZGHXpW"
      },
      "source": [
        "# ⚠️ IMPORTANT: Save Your Own Copy Before You Start!\n",
        "\n",
        "You are viewing a **read-only** notebook. Colab will let you run code and make edits, but **your changes will NOT be saved** unless you make your own copy first.\n",
        "\n",
        "> A student in a previous cohort lost all their work because they didn't do this. Don't let it happen to you!\n",
        "\n",
        "**Do this now, before anything else:**\n",
        "\n",
        "1. Go to **File → Save a copy in Drive** (or **File → Save a copy in GitHub** if you prefer)\n",
        "2. Verify that your notebook title now says **\"Copy of...\"** or is saved in your own Drive/repo\n",
        "3. Continue working **only in your copy**\n",
        "\n",
        "If you're not sure whether you're in your own copy, check the title bar at the top of the page."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwTYq7ddIgzz"
      },
      "source": [
        "# Overview\n",
        "\n",
        "At companies like Meta, detecting spam accounts and fake profiles is a core machine learning problem. Rather than analyzing what accounts *say*, these systems focus on how accounts *behave* — features like posting frequency, account age, follower-to-following ratio, and profile completeness.\n",
        "\n",
        "In this project, you will use account-level behavioral features to classify Twitter accounts as **bots** or **legitimate human users**. You will train and compare two different classifiers — logistic regression and random forest — and evaluate them using the classification metrics from class.\n",
        "\n",
        "## Learning Objectives\n",
        "- Train and compare classification models (logistic regression vs. random forest)\n",
        "- Evaluate classifiers using confusion matrices, precision, recall, F1, and ROC/AUC\n",
        "- Interpret feature importances from a tree-based model\n",
        "- Think critically about error types and their real-world consequences\n",
        "\n",
        "## Core Requirements\n",
        "1. Complete the data preprocessing (train/test split and feature scaling)\n",
        "2. Train a logistic regression model\n",
        "3. Train a random forest model\n",
        "4. Evaluate and compare both models using the provided helper function\n",
        "5. Interpret feature importances\n",
        "6. Answer the short reflection questions\n",
        "\n",
        "## Optional Enhancements (Bonus)\n",
        "- Try XGBoost or SVM\n",
        "- Hyperparameter tuning with GridSearchCV\n",
        "- Threshold tuning with precision-recall curves\n",
        "\n",
        "## Due Date\n",
        "**TODO: Fill in due date**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYHtXxCSviSR"
      },
      "source": [
        "# Getting the Dataset\n",
        "\n",
        "We will use the **Twitter Bot Accounts** dataset from Kaggle. This dataset contains ~37,000 Twitter accounts labeled as bot or human, with behavioral features like follower count, posting frequency, and account age.\n",
        "\n",
        "**Download instructions:**\n",
        "\n",
        "1. Go to: https://www.kaggle.com/datasets/davidmartngutirrez/twitter-bots-accounts/versions/2\n",
        "2. You will need a free Kaggle account to download\n",
        "3. **Important:** Download **Version 2** of the dataset (use the version selector on the page). Version 2 contains all the feature columns we need.\n",
        "4. Unzip the downloaded file. You should have a CSV file.\n",
        "5. Upload it to this Colab notebook using the cell below.\n",
        "\n",
        "**Licensing note:** This dataset is for educational use. Do not redistribute the raw data in your portfolio. Instead, link to the original Kaggle source."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RK6NgE0dgP66"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RplBoe0jo4UP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, auc, f1_score\n",
        ")\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Plot style\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (10, 6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx5TSv9DkKi2"
      },
      "source": [
        "## Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NXxT0muerJI5"
      },
      "outputs": [],
      "source": [
        "# Skipping for now while we work offline instead of on Colab\n",
        "\n",
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "imjNG3EExZZE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset shape: (37438, 20)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>default_profile</th>\n",
              "      <th>default_profile_image</th>\n",
              "      <th>description</th>\n",
              "      <th>favourites_count</th>\n",
              "      <th>followers_count</th>\n",
              "      <th>friends_count</th>\n",
              "      <th>geo_enabled</th>\n",
              "      <th>id</th>\n",
              "      <th>lang</th>\n",
              "      <th>location</th>\n",
              "      <th>profile_background_image_url</th>\n",
              "      <th>profile_image_url</th>\n",
              "      <th>screen_name</th>\n",
              "      <th>statuses_count</th>\n",
              "      <th>verified</th>\n",
              "      <th>average_tweets_per_day</th>\n",
              "      <th>account_age_days</th>\n",
              "      <th>account_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2016-10-15 21:32:11</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Blame @xaiax, Inspired by @MakingInvisible, us...</td>\n",
              "      <td>4</td>\n",
              "      <td>1589</td>\n",
              "      <td>4</td>\n",
              "      <td>False</td>\n",
              "      <td>787405734442958848</td>\n",
              "      <td>en</td>\n",
              "      <td>unknown</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/7874121826...</td>\n",
              "      <td>best_in_dumbest</td>\n",
              "      <td>11041</td>\n",
              "      <td>False</td>\n",
              "      <td>7.870</td>\n",
              "      <td>1403</td>\n",
              "      <td>bot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2016-11-09 05:01:30</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Photographing the American West since 1980. I ...</td>\n",
              "      <td>536</td>\n",
              "      <td>860</td>\n",
              "      <td>880</td>\n",
              "      <td>False</td>\n",
              "      <td>796216118331310080</td>\n",
              "      <td>en</td>\n",
              "      <td>Estados Unidos</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/8023296328...</td>\n",
              "      <td>CJRubinPhoto</td>\n",
              "      <td>252</td>\n",
              "      <td>False</td>\n",
              "      <td>0.183</td>\n",
              "      <td>1379</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2017-06-17 05:34:27</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Scruffy looking nerf herder and @twitch broadc...</td>\n",
              "      <td>3307</td>\n",
              "      <td>172</td>\n",
              "      <td>594</td>\n",
              "      <td>True</td>\n",
              "      <td>875949740503859204</td>\n",
              "      <td>en</td>\n",
              "      <td>Los Angeles, CA</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1278890453...</td>\n",
              "      <td>SVGEGENT</td>\n",
              "      <td>1001</td>\n",
              "      <td>False</td>\n",
              "      <td>0.864</td>\n",
              "      <td>1159</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2016-07-21 13:32:25</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>Wife.Godmother.Friend.Feline Fanatic! Assistan...</td>\n",
              "      <td>8433</td>\n",
              "      <td>517</td>\n",
              "      <td>633</td>\n",
              "      <td>True</td>\n",
              "      <td>756119643622735875</td>\n",
              "      <td>en</td>\n",
              "      <td>Birmingham, AL</td>\n",
              "      <td>NaN</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/1284884924...</td>\n",
              "      <td>TinkerVHELPK5</td>\n",
              "      <td>1324</td>\n",
              "      <td>False</td>\n",
              "      <td>0.889</td>\n",
              "      <td>1489</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2012-01-15 16:32:35</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>Loan coach at @mancity &amp; Aspiring DJ</td>\n",
              "      <td>88</td>\n",
              "      <td>753678</td>\n",
              "      <td>116</td>\n",
              "      <td>True</td>\n",
              "      <td>464781334</td>\n",
              "      <td>en</td>\n",
              "      <td>England, United Kingdom</td>\n",
              "      <td>http://abs.twimg.com/images/themes/theme1/bg.png</td>\n",
              "      <td>http://pbs.twimg.com/profile_images/9952566258...</td>\n",
              "      <td>JoleonLescott</td>\n",
              "      <td>4202</td>\n",
              "      <td>True</td>\n",
              "      <td>1.339</td>\n",
              "      <td>3138</td>\n",
              "      <td>human</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0           created_at  default_profile  default_profile_image  \\\n",
              "0           0  2016-10-15 21:32:11            False                  False   \n",
              "1           1  2016-11-09 05:01:30            False                  False   \n",
              "2           2  2017-06-17 05:34:27            False                  False   \n",
              "3           3  2016-07-21 13:32:25             True                  False   \n",
              "4           4  2012-01-15 16:32:35            False                  False   \n",
              "\n",
              "                                         description  favourites_count  \\\n",
              "0  Blame @xaiax, Inspired by @MakingInvisible, us...                 4   \n",
              "1  Photographing the American West since 1980. I ...               536   \n",
              "2  Scruffy looking nerf herder and @twitch broadc...              3307   \n",
              "3  Wife.Godmother.Friend.Feline Fanatic! Assistan...              8433   \n",
              "4               Loan coach at @mancity & Aspiring DJ                88   \n",
              "\n",
              "   followers_count  friends_count  geo_enabled                  id lang  \\\n",
              "0             1589              4        False  787405734442958848   en   \n",
              "1              860            880        False  796216118331310080   en   \n",
              "2              172            594         True  875949740503859204   en   \n",
              "3              517            633         True  756119643622735875   en   \n",
              "4           753678            116         True           464781334   en   \n",
              "\n",
              "                  location                      profile_background_image_url  \\\n",
              "0                  unknown  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
              "1           Estados Unidos  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
              "2          Los Angeles, CA  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
              "3           Birmingham, AL                                               NaN   \n",
              "4  England, United Kingdom  http://abs.twimg.com/images/themes/theme1/bg.png   \n",
              "\n",
              "                                   profile_image_url      screen_name  \\\n",
              "0  http://pbs.twimg.com/profile_images/7874121826...  best_in_dumbest   \n",
              "1  http://pbs.twimg.com/profile_images/8023296328...     CJRubinPhoto   \n",
              "2  http://pbs.twimg.com/profile_images/1278890453...         SVGEGENT   \n",
              "3  http://pbs.twimg.com/profile_images/1284884924...    TinkerVHELPK5   \n",
              "4  http://pbs.twimg.com/profile_images/9952566258...    JoleonLescott   \n",
              "\n",
              "   statuses_count  verified  average_tweets_per_day  account_age_days  \\\n",
              "0           11041     False                   7.870              1403   \n",
              "1             252     False                   0.183              1379   \n",
              "2            1001     False                   0.864              1159   \n",
              "3            1324     False                   0.889              1489   \n",
              "4            4202      True                   1.339              3138   \n",
              "\n",
              "  account_type  \n",
              "0          bot  \n",
              "1        human  \n",
              "2        human  \n",
              "3        human  \n",
              "4        human  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('twitter_human_bots_dataset.csv')\n",
        "print(f'Dataset shape: {df.shape}')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xezzgTLoFOH3"
      },
      "source": [
        "# Exploratory Data Analysis\n",
        "\n",
        "This section is pre-completed. Read through the plots and observations — they will inform the modeling decisions later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpZQZk8ksCsd"
      },
      "source": [
        "## Column Descriptions\n",
        "\n",
        "**TODO (Instructor):** After loading the dataset, fill in this section with:\n",
        "- A table or list describing what each column represents\n",
        "- Note which columns are features vs. identifiers vs. the target label\n",
        "- Note data types (numeric, boolean, text, etc.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpmPgVoc1IMS"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Display basic dataset info\n",
        "# df.info()\n",
        "# df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yotjMmPIWRW9"
      },
      "source": [
        "## Class Balance\n",
        "\n",
        "**TODO (Instructor):** Plot the distribution of bot vs. human labels. Annotate with percentages. Note the class ratio and whether it is balanced enough to use accuracy, or whether we need to rely on other metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAWqbCBSklf5"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Class balance bar chart\n",
        "# Example:\n",
        "# df['label_column'].value_counts().plot(kind='bar')\n",
        "# plt.title('Class Distribution: Bot vs Human')\n",
        "# plt.ylabel('Count')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B3laQ0o4Nvn"
      },
      "source": [
        "## Feature Distributions: Bot vs. Human\n",
        "\n",
        "**TODO (Instructor):** Create side-by-side or overlapping distribution plots for key behavioral features, split by class (bot vs. human). Good candidates include:\n",
        "- Follower count\n",
        "- Friend/following count\n",
        "- Statuses (tweet) count\n",
        "- Favourites count\n",
        "- Account age\n",
        "- Average tweets per day\n",
        "\n",
        "Note: Many of these features are likely heavily skewed. Consider using log-scale or log-transformed plots for readability. Write a brief observation after each plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezChoHG4LJIo"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Feature distribution plots, bot vs human\n",
        "# Consider using log scale for skewed features\n",
        "# Write observations as markdown cells after the plots"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls3VdtMENo8k"
      },
      "source": [
        "## Correlation Analysis\n",
        "\n",
        "**TODO (Instructor):** Create a correlation heatmap of the numeric features. Note any highly correlated pairs and whether any features are strongly correlated with the target label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksxq3bJSLe8Q"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Correlation heatmap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0dR1g7bRzPW"
      },
      "source": [
        "## EDA Summary\n",
        "\n",
        "**TODO (Instructor):** Write a brief summary (bullet points) of the key findings from EDA that are relevant to modeling. For example:\n",
        "- The class ratio is approximately X% bot / Y% human\n",
        "- Features A, B, C show the clearest separation between bots and humans\n",
        "- Features D and E are highly correlated with each other\n",
        "- Several features are heavily right-skewed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXK8bC4Zbxdg"
      },
      "source": [
        "# Data Preprocessing\n",
        "\n",
        "The feature selection, engineering, and cleanup steps have been completed for you. Your tasks in this section are to **split the data** and **scale the features**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcdwdWKNqzZo"
      },
      "source": [
        "## Feature Selection\n",
        "\n",
        "**TODO (Instructor):** Drop non-useful columns (IDs, raw text fields like screen_name or description, etc.). Explain briefly why each is dropped (e.g., \"screen_name is a unique identifier, not a predictive feature\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "napwMQFwhaZv"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Drop non-useful columns\n",
        "# Example:\n",
        "# df = df.drop(columns=['id', 'screen_name', 'description', ...])\n",
        "# print(f'Remaining columns: {list(df.columns)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmn7RPs1ZJRc"
      },
      "source": [
        "## Feature Engineering\n",
        "\n",
        "**TODO (Instructor):** Create 2-3 derived features that capture behavioral signals. For example:\n",
        "- `follower_friend_ratio`: followers / (friends + 1) — how \"popular\" is the account relative to how many it follows?\n",
        "- `follower_acq_rate`: followers / account_age_days — how fast did the account gain followers?\n",
        "- `tweets_per_day`: (if not already in the dataset) statuses / account_age_days\n",
        "\n",
        "Explain the intuition for each: why might this feature help distinguish bots from real users?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMD0pYwzgkJU"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Feature engineering\n",
        "# Example:\n",
        "# df['follower_friend_ratio'] = df['followers_count'] / (df['friends_count'] + 1)\n",
        "# df['follower_acq_rate'] = df['followers_count'] / (df['account_age_days'] + 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEina8lGT8BQ"
      },
      "source": [
        "## Handle Missing Values\n",
        "\n",
        "**TODO (Instructor):** Check for and handle any missing values. Document the approach taken."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1M4wR69EDOe"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Handle missing values\n",
        "# print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IP8z9kBV9K8y"
      },
      "source": [
        "## Prepare Features and Target\n",
        "\n",
        "**TODO (Instructor):** Separate features (X) and target (y). Make sure the target is the bot/human label column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SSnOhCIV3rs"
      },
      "outputs": [],
      "source": [
        "# TODO (Instructor): Define X and y\n",
        "# X = df.drop(columns=['label_column'])\n",
        "# y = df['label_column']\n",
        "# print(f'Features shape: {X.shape}')\n",
        "# print(f'Target distribution:\\n{y.value_counts()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2Sp4pOPnl9U"
      },
      "source": [
        "## Train/Test Split\n",
        "\n",
        "Split the data into training and test sets.\n",
        "\n",
        "**Requirements:**\n",
        "- Use an 80/20 split\n",
        "- Use `random_state=42` for reproducibility\n",
        "- Use stratification to preserve the class ratio in both sets\n",
        "\n",
        "*Hint: check the `stratify` parameter of `train_test_split`.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYKfx6bAfId1"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Split the data into training and test sets\n",
        "# X_train, X_test, y_train, y_test = ...\n",
        "\n",
        "\n",
        "\n",
        "# Verify the split\n",
        "print(f'Training set: {X_train.shape[0]} samples')\n",
        "print(f'Test set:     {X_test.shape[0]} samples')\n",
        "print(f'\\nTraining class distribution:\\n{y_train.value_counts(normalize=True).round(3)}')\n",
        "print(f'\\nTest class distribution:\\n{y_test.value_counts(normalize=True).round(3)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdNCfh6oXPzD"
      },
      "source": [
        "## Feature Scaling\n",
        "\n",
        "Standardize the features so each has mean 0 and standard deviation 1. This is important for logistic regression, which is sensitive to feature scales.\n",
        "\n",
        "**Requirements:**\n",
        "- Use `StandardScaler`\n",
        "- **Fit** the scaler on the training set only\n",
        "- **Transform** both the training and test sets\n",
        "\n",
        "*Why fit on train only? To avoid data leakage — the test set should be treated as unseen data.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ty7mqfznpbL"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Scale the features\n",
        "# scaler = StandardScaler()\n",
        "# X_train_scaled = ...\n",
        "# X_test_scaled = ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKTGgG9RQoqb"
      },
      "source": [
        "# Model 1: Logistic Regression (Baseline)\n",
        "\n",
        "Start with logistic regression as a baseline. It's fast, interpretable, and gives us a reference point for comparison. If a more complex model can't beat logistic regression, the added complexity isn't worth it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXfzlOJ1kwpA"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Train a logistic regression model\n",
        "# - Initialize LogisticRegression (use max_iter=1000 to ensure convergence)\n",
        "# - Fit on the SCALED training data\n",
        "# - Generate predictions on the SCALED test data\n",
        "# - Generate predicted probabilities on the SCALED test data (use .predict_proba())\n",
        "#   Note: predict_proba returns probabilities for BOTH classes.\n",
        "#   You want the probability of the positive class (bot), which is typically the second column: [:, 1]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBksDOcoeQcu"
      },
      "source": [
        "# Model 2: Random Forest\n",
        "\n",
        "Now train a random forest — an ensemble of decision trees that handles nonlinear relationships and feature interactions without needing explicit feature engineering. Random forests are also less sensitive to feature scaling, but we'll use the scaled data for consistency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKSCc56ukkZ0"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Train a random forest classifier\n",
        "# - Initialize RandomForestClassifier with n_estimators=200 and random_state=42\n",
        "# - Fit on the SCALED training data\n",
        "# - Generate predictions on the SCALED test data\n",
        "# - Generate predicted probabilities on the SCALED test data (positive class: [:, 1])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtUcTpG4U5oD"
      },
      "source": [
        "# Evaluation & Comparison\n",
        "\n",
        "Use the helper function below to evaluate both models. It will print a classification report, plot a confusion matrix, and plot a ROC curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvsSAL1YQE1d"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model_name, y_true, y_pred, y_proba):\n",
        "    \"\"\"Print classification report, plot confusion matrix and ROC curve for a model.\"\"\"\n",
        "\n",
        "    print(f'=== {model_name} ===')\n",
        "    print()\n",
        "    print(classification_report(y_true, y_pred, digits=3))\n",
        "\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    # Confusion matrix\n",
        "    ConfusionMatrixDisplay.from_predictions(\n",
        "        y_true, y_pred, ax=axes[0], cmap='Blues', colorbar=False\n",
        "    )\n",
        "    axes[0].set_title(f'{model_name} — Confusion Matrix')\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    axes[1].plot(fpr, tpr, color='steelblue', lw=2, label=f'AUC = {roc_auc:.3f}')\n",
        "    axes[1].plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Random (AUC = 0.5)')\n",
        "    axes[1].set_xlabel('False Positive Rate')\n",
        "    axes[1].set_ylabel('True Positive Rate')\n",
        "    axes[1].set_title(f'{model_name} — ROC Curve')\n",
        "    axes[1].legend(loc='lower right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThRUGef4HQH2"
      },
      "source": [
        "## Evaluate Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EiflmQLYabE6"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Call evaluate_model for logistic regression\n",
        "# evaluate_model('Logistic Regression', y_test, y_pred_lr, y_proba_lr)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIO2HZz4iIKB"
      },
      "source": [
        "## Evaluate Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PrJd4Su8IJM7"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE: Call evaluate_model for random forest\n",
        "# evaluate_model('Random Forest', y_test, y_pred_rf, y_proba_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiUcMMLgWyyA"
      },
      "source": [
        "## Model Comparison Questions\n",
        "\n",
        "Answer each question in 1–2 sentences.\n",
        "\n",
        "**1.** Which model had higher F1 score on the **bot** class?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "**2.** Look at the confusion matrices. Which model produces more **false positives** (real users wrongly flagged as bots)? Which produces more **false negatives** (bots that slip through)?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "**3.** Imagine this model is deployed on a real social media platform. Which type of error is more damaging: banning a real user (false positive) or letting a bot through (false negative)?\n",
        "\n",
        "*Your answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POqy59AKbHzZ"
      },
      "source": [
        "# Feature Importance\n",
        "\n",
        "One advantage of random forests is that they provide a built-in measure of feature importance — how much each feature contributes to reducing impurity across all trees in the forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTOj4AE8P6Yh"
      },
      "outputs": [],
      "source": [
        "# Feature importance from the random forest model (pre-filled)\n",
        "\n",
        "# NOTE: If you used different variable names for your random forest model or feature matrix,\n",
        "# update 'rf_model' and 'X_train_scaled' below to match your code.\n",
        "\n",
        "feature_names = X.columns  # original feature names before scaling\n",
        "importances = rf_model.feature_importances_\n",
        "\n",
        "# Sort by importance\n",
        "sorted_idx = np.argsort(importances)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "ax.barh(range(len(sorted_idx)), importances[sorted_idx], color='steelblue')\n",
        "ax.set_yticks(range(len(sorted_idx)))\n",
        "ax.set_yticklabels(feature_names[sorted_idx])\n",
        "ax.set_xlabel('Feature Importance (Gini)')\n",
        "ax.set_title('Random Forest — Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4zBhMXGyhLe"
      },
      "source": [
        "## Feature Importance Questions\n",
        "\n",
        "**1.** What are the top 3 most important features according to the random forest?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "**2.** Does this match what you saw in the EDA plots above? (Yes/no, plus one sentence explaining why.)\n",
        "\n",
        "*Your answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twlqYjH7ulMO"
      },
      "source": [
        "# Reflection\n",
        "\n",
        "Answer each question in 1–2 sentences.\n",
        "\n",
        "**1.** What was the main advantage of random forest over logistic regression on this problem (or vice versa)?\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "**2.** Name one thing you would try to improve this model if you had more time.\n",
        "\n",
        "*Your answer:*\n",
        "\n",
        "**3.** What's one thing you learned or found surprising in this project?\n",
        "\n",
        "*Your answer:*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmyTn6nU10tu"
      },
      "source": [
        "---\n",
        "\n",
        "# Optional Enhancements\n",
        "\n",
        "The sections below are **not required**. They are opportunities to explore further if you have time and interest. Starter code is provided to help you get going."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WhiQjShCr9d"
      },
      "source": [
        "## Enhancement A: Try XGBoost\n",
        "\n",
        "XGBoost is a gradient boosting library that often achieves state-of-the-art results on tabular data. Train an XGBoost classifier and compare it to your previous models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ni5TpveVwg09"
      },
      "outputs": [],
      "source": [
        "# Optional: XGBoost\n",
        "# First, install xgboost if needed (uncomment the line below)\n",
        "# !pip install xgboost\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    max_depth=5,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "# YOUR CODE: Fit the model, generate predictions and probabilities, then evaluate\n",
        "# xgb_model.fit(...)\n",
        "# y_pred_xgb = ...\n",
        "# y_proba_xgb = ...\n",
        "# evaluate_model('XGBoost', y_test, y_pred_xgb, y_proba_xgb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoCkZINJMUbD"
      },
      "source": [
        "## Enhancement B: Hyperparameter Tuning\n",
        "\n",
        "Use grid search with cross-validation to find better hyperparameters for your random forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQV0q4fjwtxM"
      },
      "outputs": [],
      "source": [
        "# Optional: Hyperparameter tuning with GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [10, 20, None],\n",
        "    'min_samples_split': [2, 5],\n",
        "}\n",
        "\n",
        "# YOUR CODE: Run grid search\n",
        "# grid_search = GridSearchCV(\n",
        "#     estimator=RandomForestClassifier(random_state=42),\n",
        "#     param_grid=param_grid,\n",
        "#     cv=5,\n",
        "#     scoring='f1',\n",
        "#     n_jobs=-1,\n",
        "#     verbose=1\n",
        "# )\n",
        "# grid_search.fit(X_train_scaled, y_train)\n",
        "# print(f'Best parameters: {grid_search.best_params_}')\n",
        "# print(f'Best CV F1 score: {grid_search.best_score_:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KeZKYjw6Edt"
      },
      "source": [
        "## Enhancement C: Threshold Tuning\n",
        "\n",
        "The default classification threshold is 0.5, but the optimal threshold depends on how you want to balance precision and recall. Plot the precision-recall curve and experiment with different thresholds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qiek9mMJ9vCS"
      },
      "outputs": [],
      "source": [
        "# Optional: Precision-Recall curve and threshold tuning\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "\n",
        "# Plot precision-recall curve for your best model\n",
        "# Example using random forest probabilities:\n",
        "# PrecisionRecallDisplay.from_predictions(y_test, y_proba_rf)\n",
        "# plt.title('Random Forest — Precision-Recall Curve')\n",
        "# plt.show()\n",
        "\n",
        "# Try a custom threshold:\n",
        "# custom_threshold = 0.6  # experiment with different values\n",
        "# y_pred_custom = (y_proba_rf >= custom_threshold).astype(int)\n",
        "# print(f'\\nResults at threshold = {custom_threshold}:')\n",
        "# print(classification_report(y_test, y_pred_custom, digits=3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgFw3R0NHaUr"
      },
      "source": [
        "## Enhancement D: Try an SVM\n",
        "\n",
        "Support Vector Machines find the maximum-margin decision boundary between classes. Try an SVM with an RBF kernel and compare to your other models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqG7lCzKt23n"
      },
      "outputs": [],
      "source": [
        "# Optional: SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(\n",
        "    kernel='rbf',\n",
        "    probability=True,  # needed for predict_proba and ROC curves\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# YOUR CODE: Fit the model, generate predictions and probabilities, then evaluate\n",
        "# Note: SVM can be slow on large datasets. If it takes too long, try using a\n",
        "# subset of the training data, e.g. X_train_scaled[:5000]\n",
        "\n",
        "# svm_model.fit(...)\n",
        "# y_pred_svm = ...\n",
        "# y_proba_svm = ...\n",
        "# evaluate_model('SVM (RBF)', y_test, y_pred_svm, y_proba_svm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOHsWzRrNNUz"
      },
      "source": [
        "---\n",
        "\n",
        "# Submission Checklist\n",
        "\n",
        "Before submitting, make sure you have:\n",
        "\n",
        "- [ ] Train/test split with stratification\n",
        "- [ ] Features scaled with StandardScaler (fit on train only)\n",
        "- [ ] Logistic regression model trained and evaluated\n",
        "- [ ] Random forest model trained and evaluated\n",
        "- [ ] Model comparison questions answered\n",
        "- [ ] Feature importance questions answered\n",
        "- [ ] Reflection questions answered\n",
        "\n",
        "**To submit:** Share a link to your completed notebook (Google Drive or GitHub)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
